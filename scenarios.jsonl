{"name": "tool-executor-panic-recovery", "description": "Validates that before hooks can panic without crashing tool execution", "given": ["A tool executor with registered tools", "A before hook that panics"], "when": ["Tool execution is requested"], "then": ["Execution completes successfully", "Panic is logged to stderr", "Subsequent hooks still execute"], "validates": ["tool/executor.go panic recovery", "Error logging for hook failures"]}
{"name": "agent-hierarchy-spawn-cleanup", "description": "Validates concurrent agent spawning and cleanup operations", "given": ["A root agent with registry and LLM client", "Multiple goroutines spawning children"], "when": ["Children are spawned concurrently", "Children are removed individually and in bulk"], "then": ["All spawns succeed without race conditions", "RemoveChild removes single child", "RemoveAllChildren removes all children"], "validates": ["agent/agent.go SpawnChild lock optimization", "agent/agent.go RemoveChild and RemoveAllChildren"]}
{"name": "agent-config-caching", "description": "Validates lazy Config() initialization avoids repeated deep copies", "given": ["An agent with tool configuration (AllowedTools, DeniedTools)"], "when": ["Config() is called many times concurrently"], "then": ["All calls return consistent data", "Performance is good (caching works)", "Note: returned config should not be modified per documentation"], "validates": ["agent/agent.go sync.Once lazy initialization", "Performance optimization for frequently-called method"]}
{"name": "coordinator-cache-race-condition", "description": "Validates cache lock upgrade pattern has no race condition", "given": ["A TTL cache with short expiration times"], "when": ["Many goroutines read and write with expiring items"], "then": ["No race condition panic occurs", "Expired items are properly cleaned up", "Test completes without data races"], "validates": ["coordinator/cache.go lock upgrade fix", "Proper read lock release before write lock acquisition"]}
{"name": "filtered-registry-count-optimization", "description": "Validates Count() method counts directly without allocating full slice", "given": ["A registry with many tools (100+)", "A filtered registry allowing subset of tools"], "when": ["Count() is called many times"], "then": ["Correct count is returned", "Performance is reasonable (no excessive allocation)"], "validates": ["tool/filter.go Count() optimization", "O(n) counting without slice allocation"]}
{"name": "orchestrator-context-cancellation", "description": "Validates orchestrator checks context before each tool execution", "given": ["An agent with a slow tool", "LLM that requests multiple tool calls"], "when": ["Run is called with a timeout context"], "then": ["Context cancellation is detected", "Not all tool calls complete", "Error is propagated correctly"], "validates": ["orchestrator/orchestrator.go context checks", "Proper context propagation in tool execution loop"]}
{"name": "real-anthropic-llm-integration", "description": "Validates library works with actual Anthropic Claude API", "given": ["ANTHROPIC_API_KEY environment variable set", "Real AnthropicClient with tool registration"], "when": ["Agent runs task requiring tool use"], "then": ["API call succeeds", "Tool is invoked", "Task completes without error"], "validates": ["llm/anthropic.go real API integration", "End-to-end agent workflow with Anthropic"]}
{"name": "real-openai-llm-integration", "description": "Validates library works with actual OpenAI API", "given": ["OPENAI_API_KEY environment variable set", "Real OpenAIClient with tool registration"], "when": ["Agent runs task requiring tool use"], "then": ["API call succeeds", "Tool is invoked", "Task completes without error"], "validates": ["llm/openai.go real API integration", "End-to-end agent workflow with OpenAI"]}
{"name": "concurrent-run-safety", "description": "Validates mutex prevents race conditions on concurrent Run() calls", "given": ["Single agent instance", "Multiple goroutines calling Run() concurrently"], "when": ["50 concurrent Run() calls are made"], "then": ["No race conditions detected (with -race flag)", "All calls complete without panic", "Agent state remains consistent"], "validates": ["orchestrator/orchestrator.go mutex fix", "agent/agent.go concurrent access safety"]}
{"name": "tool-input-validation-malformed", "description": "Validates library handles malformed tool inputs gracefully", "given": ["Tool executor with typed tools"], "when": ["Execute called with nil, empty, wrong-type, or extreme inputs"], "then": ["No panic occurs", "Graceful handling (error or default behavior)", "System remains stable"], "validates": ["tool/executor.go input handling", "Defensive programming patterns"]}
{"name": "tool-input-validation-type-coercion", "description": "Validates JSON type coercion edge cases", "given": ["Tool that checks parameter types"], "when": ["Execute called with float64, zero, bool, nil values"], "then": ["Types are correctly identified", "No type assertion panics", "Consistent behavior across types"], "validates": ["tool/executor.go type handling", "JSON unmarshaling edge cases"]}
{"name": "mcp-tool-adapter-integration", "description": "Validates MCP tools integrate correctly via adapter", "given": ["MCP ToolProvider with multiple tools", "ToolManager and Registry"], "when": ["Tools are refreshed and registered", "MCP tool is executed"], "then": ["Tools appear in registry", "Execution succeeds through adapter", "Results are correctly converted"], "validates": ["mcp/adapter.go ToolAdapter", "mcp/adapter.go ToolManager.RegisterAll"]}
{"name": "mcp-tool-error-propagation", "description": "Validates MCP tool errors propagate correctly", "given": ["MCP provider that returns errors"], "when": ["Failing MCP tool is executed"], "then": ["Error is propagated to caller", "Error result object is created", "Success=false in result"], "validates": ["mcp/adapter.go error handling", "Error result creation pattern"]}
{"name": "real-streaming-response", "description": "Validates streaming works end-to-end with actual LLM API", "given": ["ANTHROPIC_API_KEY set", "Real AnthropicClient"], "when": ["CreateMessageStream is called with a prompt"], "then": ["MessageStart event received", "ContentDelta events with text chunks received", "MessageStop event received"], "validates": ["llm/anthropic.go CreateMessageStream", "Streaming event handling"]}
{"name": "rate-limiter-concurrent-load", "description": "Validates token bucket correctly throttles concurrent requests", "given": ["RateLimiter with 5 tokens capacity, 10/sec refill"], "when": ["20 goroutines each request 1 token concurrently"], "then": ["All requests eventually succeed", "Total time reflects rate limiting (~1.5s)", "No race conditions with -race flag"], "validates": ["coordinator/ratelimiter.go Take", "Token bucket algorithm correctness"]}
{"name": "event-bus-multi-subscriber", "description": "Validates events are delivered to all subscribers", "given": ["EventBus with 5 subscribers"], "when": ["10 events are published, then bus is closed"], "then": ["All subscribers receive all 11 events (10 + complete)", "No events lost", "Clean shutdown on Close()"], "validates": ["orchestrator/events.go EventBus", "Pub/sub delivery guarantees"]}
{"name": "full-tool-round-trip", "description": "Validates complete tool call cycle with real LLM", "given": ["Agent with real Anthropic client", "Tool that returns specific verifiable data"], "when": ["Agent asked to use tool and report result"], "then": ["Tool is called", "Result returned to LLM", "Agent completes successfully"], "validates": ["End-to-end agent workflow", "Tool result integration with LLM"]}
{"name": "agent-child-tool-inheritance", "description": "Validates child agents inherit filtered tools from parent", "given": ["Parent agent with multiple tools", "Child spawned with AllowedTools filter"], "when": ["Child config is inspected", "Parent-child relationships checked"], "then": ["Child has correct AllowedTools", "Parent() returns correct parent", "Child appears in parent's Children()"], "validates": ["agent/agent.go SpawnChild", "Tool filtering inheritance"]}
{"name": "subagent-task-execution-anthropic", "description": "Validates child agent runs tasks with real Anthropic API", "given": ["Parent agent with Anthropic client", "Child spawned with tool access"], "when": ["Child runs task requiring tool use"], "then": ["Task completes successfully", "Tool was called", "Counter incremented"], "validates": ["agent/agent.go SpawnChild with real LLM", "Child agent Run() with Anthropic"]}
{"name": "subagent-task-execution-openai", "description": "Validates child agent runs tasks with real OpenAI API", "given": ["Parent agent with OpenAI client", "Child spawned with tool access"], "when": ["Child runs task requiring tool use"], "then": ["Task completes successfully", "Tool was called", "Counter incremented"], "validates": ["agent/agent.go SpawnChild with real LLM", "Child agent Run() with OpenAI"]}
{"name": "multi-agent-hierarchy-mixed-providers", "description": "Validates complex hierarchy with different LLM providers", "given": ["Parent with Anthropic", "Children with Anthropic and OpenAI respectively"], "when": ["Both children execute tasks concurrently"], "then": ["Both complete successfully", "Shared state correctly updated", "Hierarchy maintained"], "validates": ["Multi-provider agent orchestration", "Concurrent child execution"]}
{"name": "real-mcp-server-integration", "description": "Validates MCP client with actual stdio server process", "given": ["Shell-based MCP server speaking JSON-RPC 2.0"], "when": ["Client starts, lists tools, calls tool"], "then": ["Server process spawned", "Tools listed correctly", "Tool call returns result"], "validates": ["mcp/client.go Start/ListTools/CallTool", "JSON-RPC 2.0 protocol"]}
{"name": "mcp-tools-with-agent-e2e", "description": "Validates MCP tools work through full agent workflow", "given": ["Python MCP server with weather tool", "Agent with real Anthropic LLM"], "when": ["Agent asked about weather"], "then": ["MCP tool discovered", "Tool called via agent", "Agent completes task"], "validates": ["End-to-end MCP integration", "mcp/adapter.go with real LLM"]}
{"name": "real-gemini-llm-integration", "description": "Validates library works with actual Google Gemini API", "given": ["GEMINI_API_KEY environment variable set", "Real GeminiClient with gemini-2.0-flash model"], "when": ["CreateMessage is called with simple prompt"], "then": ["API call succeeds", "Response contains expected text", "Content blocks properly populated"], "validates": ["llm/gemini.go CreateMessage", "Gemini type translation"]}
{"name": "gemini-streaming-response", "description": "Validates Gemini streaming works with real API", "given": ["GEMINI_API_KEY set", "Real GeminiClient"], "when": ["CreateMessageStream is called with a prompt"], "then": ["Multiple stream events received", "Text chunks aggregated correctly", "Channel closes on completion"], "validates": ["llm/gemini.go CreateMessageStream", "Streaming event translation from genai SDK"]}
{"name": "real-openrouter-llm-integration", "description": "Validates library works with actual OpenRouter API", "given": ["OPENROUTER_API_KEY environment variable set", "OpenRouterClient with llama model"], "when": ["CreateMessage is called with simple prompt"], "then": ["API call succeeds via OpenRouter gateway", "Response contains expected text", "OpenAI-compatible format works"], "validates": ["llm/openrouter.go CreateMessage", "OpenAI SDK with custom base URL"]}
{"name": "openrouter-streaming-response", "description": "Validates OpenRouter streaming works with real API", "given": ["OPENROUTER_API_KEY set", "OpenRouterClient"], "when": ["CreateMessageStream is called with a prompt"], "then": ["Multiple stream events received", "Text chunks aggregated correctly", "Channel closes on completion"], "validates": ["llm/openrouter.go CreateMessageStream", "OpenAI streaming via OpenRouter gateway"]}
{"name": "real-ollama-llm-integration", "description": "Validates library works with local Ollama instance", "given": ["Ollama running on localhost:11434", "OllamaClient with llama3.2:1b model"], "when": ["CreateMessage is called with simple prompt"], "then": ["API call succeeds to local Ollama", "Response contains expected text", "OpenAI-compatible format works"], "validates": ["llm/ollama.go CreateMessage", "OpenAI SDK with local base URL"]}
{"name": "ollama-streaming-response", "description": "Validates Ollama streaming works with local instance", "given": ["Ollama running on localhost:11434", "OllamaClient with llama3.2:1b model"], "when": ["CreateMessageStream is called with a prompt"], "then": ["Multiple stream events received", "Text chunks aggregated correctly", "Channel closes on completion"], "validates": ["llm/ollama.go CreateMessageStream", "OpenAI streaming via local Ollama"]}
{"name": "gemini-tool-calling", "description": "Validates Gemini tool calling works with real API", "given": ["GEMINI_API_KEY set", "Agent with GeminiClient and increment_counter tool"], "when": ["Agent runs task requiring tool use"], "then": ["Tool is called", "Counter incremented", "Task completes successfully"], "validates": ["llm/gemini.go tool calling", "orchestrator/orchestrator.go tool result with Name field for Gemini"]}
{"name": "openrouter-tool-calling", "description": "Validates OpenRouter tool calling works with real API", "given": ["OPENROUTER_API_KEY set", "Agent with OpenRouterClient and increment_counter tool"], "when": ["Agent runs task requiring tool use"], "then": ["Tool is called", "Counter incremented", "Task completes successfully"], "validates": ["llm/openrouter.go tool calling", "OpenAI-compatible tool format via gateway"]}
{"name": "ollama-tool-calling", "description": "Validates Ollama tool calling works with local instance", "given": ["Ollama running on localhost:11434", "Agent with OllamaClient and increment_counter tool"], "when": ["Agent runs task requiring tool use"], "then": ["Tool may or may not be called (small models unreliable)", "No errors occur", "System remains stable"], "validates": ["llm/ollama.go tool calling", "Graceful handling of unreliable tool use"]}
{"name": "gemini-subagent-task", "description": "Validates child agent runs tasks with real Gemini API", "given": ["Parent agent with GeminiClient", "Child spawned with tool access"], "when": ["Child runs task requiring tool use"], "then": ["Task completes successfully", "Tool was called", "Counter incremented"], "validates": ["agent/agent.go SpawnChild with Gemini LLM", "Child agent Run() with Gemini"]}
{"name": "openrouter-subagent-task", "description": "Validates child agent runs tasks with real OpenRouter API", "given": ["Parent agent with OpenRouterClient", "Child spawned with tool access"], "when": ["Child runs task requiring tool use"], "then": ["Task completes successfully", "Tool was called", "Counter incremented"], "validates": ["agent/agent.go SpawnChild with OpenRouter LLM", "Child agent Run() with OpenRouter"]}
{"name": "mixed-provider-hierarchy", "description": "Validates complex hierarchy with Gemini parent and OpenRouter child", "given": ["Parent with GeminiClient", "Child with OpenRouterClient", "Shared counter tool"], "when": ["Both parent and child execute tasks"], "then": ["Both complete successfully", "Shared counter incremented by both", "Different providers work in same hierarchy"], "validates": ["Multi-provider agent orchestration", "Cross-provider tool execution"]}
